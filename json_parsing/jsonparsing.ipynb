{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2713f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LIFE\\_BOOTCAMP_MANDIRI\\B9_RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "179f8e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: Laptopnya kencang buat coding, mantap!\n",
      "Metadata: {'source': 'D:\\\\LIFE\\\\_BOOTCAMP_MANDIRI\\\\B9_RAG\\\\json_parsing\\\\data\\\\data.json', 'seq_num': 1, 'user': 'farhan_99', 'rating': 5}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "# --- TANTANGAN 1: Lengkapi Fungsi Metadata ---\n",
    "def ambil_metadata(record, metadata):\n",
    "    # record adalah satu kotak data pembeli (misal: farhan_99)\n",
    "    metadata[\"user\"] = record.get(\"username\")   # <--- Isi nama field JSON-nya\n",
    "    metadata[\"rating\"] = record.get(\"bintang\") # <--- Isi nama field JSON-nya\n",
    "    return metadata\n",
    "\n",
    "# --- TANTANGAN 2: Setup Loader ---\n",
    "loader = JSONLoader(\n",
    "    file_path='data/data.json',\n",
    "    \n",
    "    # Petunjuk: Masuk ke 'data_toko', lalu ke 'komentar_pembeli', lalu pecah list-nya.\n",
    "    jq_schema='.data_toko.komentar_pembeli[]', # <--- Lengkapi path-nya\n",
    "    \n",
    "    # Petunjuk: Field mana yang mau dibaca sebagai teks utama?\n",
    "    content_key='isi_review', # <--- Isi nama field JSON-nya\n",
    "    \n",
    "    metadata_func=ambil_metadata\n",
    ")\n",
    "\n",
    "# Jalankan\n",
    "docs = loader.load()\n",
    "\n",
    "# Cek Hasil\n",
    "print(f\"Content: {docs[0].page_content}\")\n",
    "print(f\"Metadata: {docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374f0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Diskusi: 3\n",
      "========================================\n",
      "Topik    : Error saat install Python\n",
      "Penulis  : koding_mula\n",
      "Masalah  : Kenapa muncul error 'Path not found' saat saya ketik python di CMD?\n",
      "--------------------\n",
      "Topik    : LangChain susah dimengerti\n",
      "Penulis  : farhan_dev\n",
      "Masalah  : Ada yang punya tutorial bahasa Indonesia soal JSONLoader? Saya bingung.\n",
      "--------------------\n",
      "Topik    : Laptop panas\n",
      "Penulis  : gamer_tobat\n",
      "Masalah  : Laptop saya bunyi kipasnya kencang saat training model YOLO.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "# --- TANTANGAN 1: Metadata Bersarang ---\n",
    "def get_forum_meta(record, metadata):\n",
    "    # record adalah satu kotak diskusi\n",
    "    \n",
    "    # Ambil Topik sebagai metadata\n",
    "    metadata[\"judul_topik\"] = record.get(\"topic\")\n",
    "    \n",
    "    # TANTANGAN UTAMA: Ambil username (ada di dalam author)\n",
    "    # Hint: record.get(\"author\") akan menghasilkan {username:..., level:...}\n",
    "    # Jadi caranya: record.get(\"author\").get(\"...\")\n",
    "    metadata[\"penulis\"] = record.get(\"author\").get(\"username\")\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# --- TANTANGAN 2: Setup Loader ---\n",
    "loader = JSONLoader(\n",
    "    file_path='data/forum_data.json',\n",
    "    \n",
    "    # Hint: Masuk ke 'data', lalu ke 'discussions', lalu pecah array-nya []\n",
    "    jq_schema='.data.discussions[]', \n",
    "    \n",
    "    # Hint: Kita mau AI baca curhatan user (content), bukan judulnya.\n",
    "    content_key='content', \n",
    "    \n",
    "    metadata_func=get_forum_meta\n",
    ")\n",
    "\n",
    "# Load data\n",
    "docs = loader.load()\n",
    "\n",
    "# --- VERIFIKASI (Tampilkan Semua Data) ---\n",
    "print(f\"Total Diskusi: {len(docs)}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"Topik    : {doc.metadata['judul_topik']}\")\n",
    "    print(f\"Penulis  : {doc.metadata['penulis']}\")\n",
    "    print(f\"Masalah  : {doc.page_content}\") # Ini harusnya isi curhatan\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2106c0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedang load model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LIFE\\_BOOTCAMP_MANDIRI\\B9_RAG\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Farhan Kamil\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CONTOH OUTPUT VECTOR (EMBEDDING) ---\n",
      "Kalimat Asli: 'Saya suka belajar koding Python'\n",
      "Dimensi Vector: (384,) (Artinya ada 384 angka)\n",
      "Tipe Data: <class 'numpy.ndarray'>\n",
      "\n",
      "Isi Vector (5 angka pertama):\n",
      "[ 0.09522366 -0.21008953 -0.46234402 -0.009131   -0.42144918]\n",
      "...\n",
      "(dan seterusnya sampai 384 angka)\n",
      "\n",
      "--- HASIL PENCARIAN KEMIRIPAN ---\n",
      "1 vs 2 (Coding vs Coding): 0.9218\n",
      "1 vs 3 (Coding vs Masak) : 0.0571\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 1. Kita load model yang support Bahasa Indonesia\n",
    "# 'paraphrase-multilingual-MiniLM-L12-v2' adalah model yang populer dan ringan\n",
    "print(\"Sedang load model...\")\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# 2. Data Input\n",
    "kalimat_1 = \"Saya suka belajar koding Python\"\n",
    "kalimat_2 = \"Aku gemar mempelajari bahasa pemrograman Python\"  # Mirip makna\n",
    "kalimat_3 = \"Ibu sedang memasak sayur lodeh di dapur\"         # Beda topik\n",
    "\n",
    "# 3. Proses Embedding (Ubah Teks jadi Angka)\n",
    "emb_1 = model.encode(kalimat_1)\n",
    "emb_2 = model.encode(kalimat_2)\n",
    "emb_3 = model.encode(kalimat_3)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# MARI KITA LIHAT OUTPUTNYA\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "print(f\"\\n--- CONTOH OUTPUT VECTOR (EMBEDDING) ---\")\n",
    "print(f\"Kalimat Asli: '{kalimat_1}'\")\n",
    "print(f\"Dimensi Vector: {emb_1.shape} (Artinya ada {len(emb_1)} angka)\")\n",
    "print(f\"Tipe Data: {type(emb_1)}\")\n",
    "print(\"\\nIsi Vector (5 angka pertama):\")\n",
    "print(emb_1[:5]) \n",
    "print(\"...\\n(dan seterusnya sampai 384 angka)\\n\")\n",
    "\n",
    "# 4. Menghitung Kemiripan (Cosine Similarity)\n",
    "score_mirip = util.cos_sim(emb_1, emb_2)\n",
    "score_beda  = util.cos_sim(emb_1, emb_3)\n",
    "\n",
    "print(f\"--- HASIL PENCARIAN KEMIRIPAN ---\")\n",
    "print(f\"1 vs 2 (Coding vs Coding): {score_mirip.item():.4f}\")\n",
    "print(f\"1 vs 3 (Coding vs Masak) : {score_beda.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3643608",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17e06ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedang memuat model...\n",
      "Sedang mengubah database jadi angka (embedding)...\n",
      "\n",
      "User Bertanya: 'Gimana kalau aku lupa kata sandi akun belajar?'\n",
      "--- HASIL PENCARIAN ---\n",
      "Dokumen Paling Relevan (Index 2):\n",
      ">> \"Cara reset password e-learning: Klik lupa sandi di menu login.\"\n",
      "Skor Confidence: 0.5702\n",
      "\n",
      "User Bertanya: 'Kapan kita mulai masuk kuliah?'\n",
      "--- HASIL PENCARIAN ---\n",
      "Dokumen Paling Relevan (Index 0):\n",
      ">> \"Jadwal kuliah semester ganjil dimulai bulan September.\"\n",
      "Skor Confidence: 0.5906\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- STEP 1: LOAD MODEL ---\n",
    "# Kita pakai model multilingual biar ngerti Indo\n",
    "print(\"Sedang memuat model...\")\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# --- STEP 2: KNOWLEDGE BASE (Pura-pura jadi Database) ---\n",
    "# Anggap ini isi dokumen PDF kampus yang sudah dipecah per kalimat\n",
    "database_dokumen = [\n",
    "    \"Jadwal kuliah semester ganjil dimulai bulan September.\",     # Doc 0\n",
    "    \"Syarat beasiswa prestasi adalah IPK minimal 3.50.\",         # Doc 1\n",
    "    \"Cara reset password e-learning: Klik lupa sandi di menu login.\", # Doc 2\n",
    "    \"Kantin buka setiap hari jam 8 pagi sampai 5 sore.\",         # Doc 3\n",
    "    \"Dilarang merokok di area lingkungan kampus.\",               # Doc 4\n",
    "]\n",
    "\n",
    "# --- STEP 3: INDEXING (Ubah Database jadi Vector) ---\n",
    "# Ini biasanya dilakukan sekali di awal (Pre-computation)\n",
    "print(\"Sedang mengubah database jadi angka (embedding)...\")\n",
    "doc_embeddings = model.encode(database_dokumen, convert_to_tensor=True)\n",
    "\n",
    "# --- STEP 4: RETRIEVAL (Proses Pencarian) ---\n",
    "def cari_jawaban(pertanyaan_user):\n",
    "    print(f\"\\nUser Bertanya: '{pertanyaan_user}'\")\n",
    "    \n",
    "    # 1. Ubah pertanyaan user jadi vector\n",
    "    query_vec = model.encode(pertanyaan_user, convert_to_tensor=True)\n",
    "    \n",
    "    # 2. Hitung kemiripan vector pertanyaan vs SEMUA vector database\n",
    "    # Ini menghitung cos_sim antara 1 query vs 5 dokumen sekaligus\n",
    "    skor_kemiripan = util.cos_sim(query_vec, doc_embeddings)[0]\n",
    "    \n",
    "    # 3. Cari index dengan skor tertinggi (Argmax)\n",
    "    # Ini mencari posisi juara 1 (paling mirip)\n",
    "    best_idx = np.argmax(skor_kemiripan.cpu().numpy())\n",
    "    best_score = skor_kemiripan[best_idx]\n",
    "    \n",
    "    # 4. Tampilkan Hasil\n",
    "    print(f\"--- HASIL PENCARIAN ---\")\n",
    "    print(f\"Dokumen Paling Relevan (Index {best_idx}):\")\n",
    "    print(f\">> \\\"{database_dokumen[best_idx]}\\\"\")\n",
    "    print(f\"Skor Confidence: {best_score:.4f}\")\n",
    "\n",
    "# --- STEP 5: TEST CASE ---\n",
    "# Kasus A: Kata kunci beda tapi makna sama (Sandi vs Password)\n",
    "cari_jawaban(\"Gimana kalau aku lupa kata sandi akun belajar?\")\n",
    "\n",
    "# Kasus B: Topik lain\n",
    "cari_jawaban(\"Kapan kita mulai masuk kuliah?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd9f06a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- HASIL PENCARIAN ---\n",
      "Dokumen Paling Relevan (Index 2):\n",
      ">> \"Farhan memiliki skill di bidang AI\"\n",
      "Skor Confidence: 0.6256\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "\n",
    "database_dokumen = [\n",
    "    \"Farhan adalah mahasiswa semester 3\",\n",
    "    \"Farhan adalah mahasiswa Itenad prodi informatika\",\n",
    "    \"Farhan memiliki skill di bidang AI\"\n",
    "]\n",
    "\n",
    "doc_embeddings = model.encode(database_dokumen, convert_to_tensor=True)\n",
    "\n",
    "def cari_jawaban(pertanyaan_user):\n",
    "    query_vec = model.encode(pertanyaan_user, convert_to_tensor=True)\n",
    "    \n",
    "    \n",
    "    skor_kemiripan = util.cos_sim(query_vec, doc_embeddings)[0]\n",
    "    \n",
    "    best_idx = np.argmax(skor_kemiripan.cpu().numpy())\n",
    "    best_score = skor_kemiripan[best_idx]\n",
    "    \n",
    "    # 4. Tampilkan Hasil\n",
    "    print(f\"--- HASIL PENCARIAN ---\")\n",
    "    print(f\"Dokumen Paling Relevan (Index {best_idx}):\")\n",
    "    print(f\">> \\\"{database_dokumen[best_idx]}\\\"\")\n",
    "    print(f\"Skor Confidence: {best_score:.4f}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "pertanyaan = input(\"Masukkan Pertanyaan tentang Farhan\")\n",
    "\n",
    "cari_jawaban(pertanyaan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ce5cf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Farhan Kamil\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|██████████| 79.3M/79.3M [04:35<00:00, 302kiB/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Cara reset password e-learning: Klik lupa sandi di menu login.']]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# 1. Bikin Client (Ibarat buka aplikasi Database-nya)\n",
    "# Data akan disimpan di folder \"my_vectordb\" di laptopmu (PERMANEN!)\n",
    "client = chromadb.PersistentClient(path=\"./my_vectordb\")\n",
    "\n",
    "# 2. Bikin Koleksi (Ibarat bikin Table di SQL)\n",
    "collection = client.get_or_create_collection(name=\"dokumen_kampus\")\n",
    "\n",
    "# 3. Masukkan Data (Ingestion)\n",
    "# Perhatikan: Kita TIDAK PERLU panggil model embedding manual.\n",
    "# ChromaDB punya default embedding model di dalamnya (all-MiniLM-L6-v2).\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"Jadwal kuliah semester ganjil dimulai bulan September.\",\n",
    "        \"Syarat beasiswa prestasi adalah IPK minimal 3.50.\",\n",
    "        \"Cara reset password e-learning: Klik lupa sandi di menu login.\"\n",
    "    ],\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\"] # ID unik tiap dokumen\n",
    ")\n",
    "\n",
    "# 4. Pencarian (Retrieval)\n",
    "# Lihat betapa simpelnya, gak perlu rumus matematika lagi!\n",
    "results = collection.query(\n",
    "    query_texts=[\"Lupa kata sandi akun belajar\"],\n",
    "    n_results=1 # Minta 1 hasil teratas\n",
    ")\n",
    "\n",
    "print(results['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "084af6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['doc1', 'doc2', 'doc3'],\n",
       " 'embeddings': array([[-0.03431543,  0.05837245, -0.00937446, ...,  0.06811058,\n",
       "         -0.07416835,  0.0167924 ],\n",
       "        [-0.03097427,  0.11782466, -0.03259042, ...,  0.04557349,\n",
       "         -0.02315447,  0.02813625],\n",
       "        [-0.06134126,  0.03819292, -0.0429939 , ...,  0.06528832,\n",
       "         -0.07310627, -0.01126526]], shape=(3, 384)),\n",
       " 'documents': ['Jadwal kuliah semester ganjil dimulai bulan September.',\n",
       "  'Syarat beasiswa prestasi adalah IPK minimal 3.50.',\n",
       "  'Cara reset password e-learning: Klik lupa sandi di menu login.'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': [None, None, None]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6541cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents= ['Farhan adalah mahasiswa semester 3'],\n",
    "    ids = ['idFarhan']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53bd0fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Farhan adalah mahasiswa semester 3']]\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"Farhan semester berapa\"],\n",
    "    n_results=1 \n",
    ")\n",
    "\n",
    "print(results['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acb77b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Jadwal kuliah semester ganjil dimulai bulan September.', 'Farhan adalah mahasiswa semester 3', 'Syarat beasiswa prestasi adalah IPK minimal 3.50.', 'Cara reset password e-learning: Klik lupa sandi di menu login.']]\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"siapa sih yang semester 3 itu?\"]\n",
    ")\n",
    "\n",
    "print(results['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79d323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
